{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23722ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce5cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"C:/Users/ankit/Downloads/Airline_Delay_Cause.csv\")\n",
    "\n",
    "# Display basic info and check for missing values\n",
    "print(df.info())\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7fc150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of outlier removal using IQR method\n",
    "Q1 = df['arr_delay'].quantile(0.30)\n",
    "Q3 = df['arr_delay'].quantile(0.70)\n",
    "IQR = Q3 - Q1\n",
    "df = df[(df['arr_delay'] >= Q1 - 1.5 * IQR) & (df['arr_delay'] <= Q3 + 1.5 * IQR)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c67f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to numeric using Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df['carrier'] = label_encoder.fit_transform(df['carrier'])\n",
    "df['airport'] = label_encoder.fit_transform(df['airport'])\n",
    "\n",
    "# Fill missing values (if any) with zero or mean (depending on the feature)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Feature engineering: Extract additional information if needed (like seasonality)\n",
    "df['season'] = df['month'].apply(lambda x: 'Winter' if x in [12, 1, 2] \n",
    "                                 else 'Spring' if x in [3, 4, 5] \n",
    "                                 else 'Summer' if x in [6, 7, 8] \n",
    "                                 else 'Fall')\n",
    "df['season'] = label_encoder.fit_transform(df['season'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84d6b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "features = ['carrier', 'arr_flights', 'arr_del15', \n",
    "            'carrier_ct', 'weather_ct', 'nas_ct', 'security_ct', 'late_aircraft_ct']\n",
    "X = df[features]\n",
    "y = df['arr_cancelled']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "754cb9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.5063656647854049\n",
      "Confusion Matrix (Random Forest):\n",
      "[[3644  272   63 ...    0    0    0]\n",
      " [1069  149   52 ...    0    0    0]\n",
      " [ 557  103   39 ...    0    0    0]\n",
      " ...\n",
      " [   2    0    0 ...    0    0    0]\n",
      " [   1    0    0 ...    0    0    0]\n",
      " [   1    0    0 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "#log_reg = LogisticRegression()\n",
    "#log_reg.fit(X_train, y_train)\n",
    "#y_pred_log = log_reg.predict(X_test)\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "#print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix (Random Forest):\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "#print(\"Classification Report (Random Forest):\")\n",
    "#print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7b0ee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5286783042394015\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.97      0.71      4045\n",
      "         1.0       0.17      0.07      0.09      1324\n",
      "         2.0       0.08      0.01      0.01       750\n",
      "         3.0       1.00      0.00      0.00       422\n",
      "         4.0       0.00      0.00      0.00       280\n",
      "         5.0       0.08      0.01      0.01       170\n",
      "         6.0       1.00      0.00      0.00       142\n",
      "         7.0       1.00      0.00      0.00        85\n",
      "         8.0       1.00      0.00      0.00        70\n",
      "         9.0       1.00      0.00      0.00        41\n",
      "        10.0       1.00      0.00      0.00        50\n",
      "        11.0       1.00      0.00      0.00        42\n",
      "        12.0       1.00      0.00      0.00        29\n",
      "        13.0       1.00      0.00      0.00        22\n",
      "        14.0       1.00      0.00      0.00        18\n",
      "        15.0       1.00      0.00      0.00        19\n",
      "        16.0       1.00      0.00      0.00        14\n",
      "        17.0       1.00      0.00      0.00        10\n",
      "        18.0       1.00      0.00      0.00        12\n",
      "        19.0       1.00      0.00      0.00         9\n",
      "        20.0       1.00      0.00      0.00         8\n",
      "        21.0       1.00      0.00      0.00         4\n",
      "        22.0       1.00      0.00      0.00         5\n",
      "        23.0       1.00      0.00      0.00         7\n",
      "        24.0       1.00      0.00      0.00         5\n",
      "        25.0       1.00      0.00      0.00         4\n",
      "        26.0       1.00      0.00      0.00         2\n",
      "        27.0       1.00      0.00      0.00         6\n",
      "        28.0       1.00      0.00      0.00         3\n",
      "        29.0       1.00      0.00      0.00         2\n",
      "        30.0       1.00      0.00      0.00         2\n",
      "        32.0       1.00      0.00      0.00         4\n",
      "        33.0       1.00      0.00      0.00         2\n",
      "        34.0       1.00      0.00      0.00         2\n",
      "        36.0       1.00      0.00      0.00         2\n",
      "        39.0       1.00      0.00      0.00         1\n",
      "        40.0       1.00      0.00      0.00         1\n",
      "        43.0       1.00      0.00      0.00         2\n",
      "        44.0       1.00      0.00      0.00         2\n",
      "        47.0       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.53      7619\n",
      "   macro avg       0.90      0.03      0.02      7619\n",
      "weighted avg       0.47      0.53      0.39      7619\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3936   96    9 ...    0    0    0]\n",
      " [1219   87   10 ...    0    0    0]\n",
      " [ 670   74    4 ...    0    0    0]\n",
      " ...\n",
      " [   0    2    0 ...    0    0    0]\n",
      " [   1    1    0 ...    0    0    0]\n",
      " [   1    0    0 ...    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Train-test split with stratification to ensure label balance\n",
    "#X_train, X_test, y_train, y_test = train_test_split(\n",
    "#    X, y, test_size=0.2, random_state=42, stratify=y\n",
    "#)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000, solver='saga', random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model with zero_division parameter in classification report\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=1))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de68a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*Question 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "468bf115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "features = ['month', 'carrier', 'airport', 'arr_flights', 'carrier_ct', \n",
    "            'weather_ct', 'nas_ct', 'security_ct', 'late_aircraft_ct']\n",
    "X = df[features]\n",
    "y = df['arr_del15']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features for Gradient Boosting\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8401125",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23824\\2400417472.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Gradient Boosting Classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgb_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgb_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_pred_gb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgb_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m         n_stages = self._fit_stages(\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m             \u001b[1;31m# fit next stage of trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[0;32m    664\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    220\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_y\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             residual = loss.negative_gradient(\n\u001b[0m\u001b[0;32m    223\u001b[0m                 \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions_copy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb_losses.py\u001b[0m in \u001b[0;36mnegative_gradient\u001b[1;34m(self, y, raw_predictions, k, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m         \"\"\"\n\u001b[0;32m    822\u001b[0m         return y - np.nan_to_num(\n\u001b[1;32m--> 823\u001b[1;33m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m         )\n\u001b[0;32m    825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\special\\_logsumexp.py\u001b[0m in \u001b[0;36mlogsumexp\u001b[1;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ma_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ma_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;31m# suppress warnings about log of zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=30, learning_rate=0.1, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(\"Confusion Matrix (Gradient Boosting):\")\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n",
    "print(\"Classification Report (Gradient Boosting):\")\n",
    "print(classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb9893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Heatmap for Gradient Boosting\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_gb), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix - Gradient Boosting\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b75333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96fc15f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
